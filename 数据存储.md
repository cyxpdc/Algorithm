传统方式：一个kv到达request进行hash后，到达指定的机器上；如果加减机器，所有的kv对需要重新计算分配

一致性哈希：所有哈希的返回值做成一个环，如果要添加机器，就将机器hash后，放到对应的位置，减机器同理；

这个结构存在的问题：

1.机器少的时候，很难均分（哈希是样本大的时候才有均分），导致某些机器存的数据多，某些机器存的数据少：

2.就算通过一些手段使1平衡了，但是加减一、两台这种很少的机器量下，还是会不均匀，每次都需要调整

如何解决：

虚拟节点技术：将几台有限的机器虚拟化成很多的机器节点（比如一台机器分1000个出来），所有的虚拟节点分到的数据到给物理机处理，这样解决了一，而且二也解决了，加减机器都会均匀位置加减

新问题：哈希冲突：概率很低，可以两台机器共同存一份，当作备份了
